{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:46.306032Z",
     "iopub.status.busy": "2025-10-21T08:10:46.306032Z",
     "iopub.status.idle": "2025-10-21T08:10:46.311157Z",
     "shell.execute_reply": "2025-10-21T08:10:46.311157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\Golds\\Downloads\\survival-readmission\n"
     ]
    }
   ],
   "source": [
    "# Ensure repository root on sys.path for `import app.*`\n",
    "import sys\n",
    "from pathlib import Path\n",
    "repo_root = (Path.cwd() / '..').resolve()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "print('Repo root:', repo_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Survival Modeling\n",
    "\n",
    "This notebook trains and evaluates survival models:\n",
    "- Cox Proportional Hazards\n",
    "- XGBoost Survival\n",
    "- Other survival models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:46.354141Z",
     "iopub.status.busy": "2025-10-21T08:10:46.351182Z",
     "iopub.status.idle": "2025-10-21T08:10:48.188209Z",
     "shell.execute_reply": "2025-10-21T08:10:48.186201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter\n",
    "from app.evaluation import compute_concordance_index, compute_td_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Feature Importance (Tree-based proxy)\n",
    "\n",
    "As a fast heuristic, train a tree-based classifier on the 30-day event label to inspect feature importances. This is a proxy (not a survival objective) to surface candidate predictors; we will follow up with survival-specific modeling (Cox, XGBoost Survival).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:48.190445Z",
     "iopub.status.busy": "2025-10-21T08:10:48.190445Z",
     "iopub.status.idle": "2025-10-21T08:10:48.614624Z",
     "shell.execute_reply": "2025-10-21T08:10:48.613601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (260, 40)\n",
      "Num lab-derived columns: 20\n",
      "Sample lab columns: ['lab_50868', 'lab_50882', 'lab_50893', 'lab_50902', 'lab_50912']\n"
     ]
    }
   ],
   "source": [
    "# Load cohort and build features\n",
    "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n",
    "\n",
    "# Build features via app.feature_engineering (includes labs when available)\n",
    "from app.feature_engineering import engineer_features\n",
    "import os\n",
    "\n",
    "# Set the MIMIC_DEMO_DIR environment variable to ensure data loader finds the data\n",
    "os.environ['MIMIC_DEMO_DIR'] = '../data/raw/mimic-iv-demo'\n",
    "\n",
    "X, y_df = engineer_features(cohort)\n",
    "y = y_df['event'].astype(int)\n",
    "\n",
    "print('Feature matrix shape:', X.shape)\n",
    "print('Num lab-derived columns:', sum([1 for col in X.columns if str(col).startswith('lab_')]))\n",
    "print('Sample lab columns:', [col for col in X.columns if str(col).startswith('lab_')][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:48.622623Z",
     "iopub.status.busy": "2025-10-21T08:10:48.621607Z",
     "iopub.status.idle": "2025-10-21T08:10:49.415427Z",
     "shell.execute_reply": "2025-10-21T08:10:49.413890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 182 samples\n",
      "Test set: 78 samples\n",
      "Event rate in train: 0.192\n",
      "Event rate in test: 0.192\n",
      "Quick AUC (30-day classification proxy): 0.692\n",
      "\n",
      "Top 15 features:\n",
      "      feature  importance\n",
      "17  lab_51265    0.091135\n",
      "20  lab_51301    0.088304\n",
      "10  lab_50983    0.065512\n",
      "18  lab_51277    0.063760\n",
      "13  lab_51222    0.061051\n",
      "4   lab_50902    0.048165\n",
      "12  lab_51221    0.044855\n",
      "19  lab_51279    0.041921\n",
      "7   lab_50960    0.041769\n",
      "3   lab_50893    0.041396\n",
      "5   lab_50912    0.041395\n",
      "6   lab_50931    0.039421\n",
      "15  lab_51249    0.034529\n",
      "9   lab_50971    0.032628\n",
      "14  lab_51248    0.032163\n"
     ]
    }
   ],
   "source": [
    "# Train/test split and RandomForest quick AUC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Simple train/test split by index (for demo; prefer temporal split in practice)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Event rate in train: {y_train.mean():.3f}\")\n",
    "print(f\"Event rate in test: {y_test.mean():.3f}\")\n",
    "\n",
    "# Quick RandomForest for feature importance (proxy, not survival-specific)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Quick AUC (30-day classification proxy)\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Quick AUC (30-day classification proxy): {auc:.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 features:\")\n",
    "print(feature_importance.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:49.422473Z",
     "iopub.status.busy": "2025-10-21T08:10:49.422473Z",
     "iopub.status.idle": "2025-10-21T08:10:49.431349Z",
     "shell.execute_reply": "2025-10-21T08:10:49.430339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load cohort from previous step (ensure variable exists before feature engineering)\n",
    "import pandas as pd\n",
    "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:49.438942Z",
     "iopub.status.busy": "2025-10-21T08:10:49.438942Z",
     "iopub.status.idle": "2025-10-21T08:10:49.805883Z",
     "shell.execute_reply": "2025-10-21T08:10:49.803874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (260, 40)\n",
      "Num lab-derived columns: 20\n"
     ]
    }
   ],
   "source": [
    "# Build features via app.feature_engineering (includes labs when available)\n",
    "from app.feature_engineering import engineer_features\n",
    "\n",
    "X, y_df = engineer_features(cohort)\n",
    "y = y_df['event'].astype(int)\n",
    "\n",
    "print('Feature matrix shape:', X.shape)\n",
    "print('Num lab-derived columns:', sum([1 for col in X.columns if str(col).startswith('lab_')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:49.808881Z",
     "iopub.status.busy": "2025-10-21T08:10:49.808881Z",
     "iopub.status.idle": "2025-10-21T08:10:49.813144Z",
     "shell.execute_reply": "2025-10-21T08:10:49.812422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\Golds\\Downloads\\survival-readmission\n"
     ]
    }
   ],
   "source": [
    "# Setup: add repo root to path for `app.*`\n",
    "import sys\n",
    "from pathlib import Path\n",
    "repo_root = (Path.cwd() / '..').resolve()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "print('Repo root:', repo_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cox Proportional Hazards (baseline)\n",
    "Fit an interpretable Cox PH model and report C-index on a holdout split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:49.820172Z",
     "iopub.status.busy": "2025-10-21T08:10:49.820172Z",
     "iopub.status.idle": "2025-10-21T08:10:50.208257Z",
     "shell.execute_reply": "2025-10-21T08:10:50.207343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cox PH C-index (holdout): 0.696\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Cox PH\n",
    "from lifelines import CoxPHFitter\n",
    "from app.evaluation import compute_concordance_index\n",
    "\n",
    "cox_df = X.copy()\n",
    "cox_df[\"time_to_event\"] = y_df[\"time_to_event\"].values\n",
    "cox_df[\"event\"] = y_df[\"event\"].values\n",
    "\n",
    "# Simple train/test split by index (for demo; prefer temporal split in practice)\n",
    "train_idx, test_idx = X_train.index, X_test.index\n",
    "cox_train = cox_df.loc[train_idx]\n",
    "cox_test = cox_df.loc[test_idx]\n",
    "\n",
    "cph = CoxPHFitter(penalizer=0.1, l1_ratio=0.1)\n",
    "cph.fit(cox_train.assign(event=cox_train[\"event\"].astype(bool)), duration_col=\"time_to_event\", event_col=\"event\", show_progress=False)\n",
    "\n",
    "# Risk scores and C-index\n",
    "risk_scores = cph.predict_partial_hazard(cox_test)\n",
    "c_index = compute_concordance_index(cox_test[\"event\"], cox_test[\"time_to_event\"], risk_scores)\n",
    "print(f\"Cox PH C-index (holdout): {c_index:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Survival (Cox objective)\n",
    "Train an XGBoost model with survival:cox to produce risk scores and compute C-index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:50.210907Z",
     "iopub.status.busy": "2025-10-21T08:10:50.209894Z",
     "iopub.status.idle": "2025-10-21T08:10:50.553289Z",
     "shell.execute_reply": "2025-10-21T08:10:50.549684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cox C-index (holdout): 0.622\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Prepare DMatrix for XGBoost Cox\n",
    "# For Cox, label is time; event is provided implicitly via order weighting\n",
    "# We'll follow the typical approach: sort by time and pass (time, event) via special settings.\n",
    "\n",
    "# Create DMatrix with features\n",
    "dtrain = xgb.DMatrix(X_train, label=y_df.loc[X_train.index, 'time_to_event'].values)\n",
    "dtest = xgb.DMatrix(X_test, label=y_df.loc[X_test.index, 'time_to_event'].values)\n",
    "\n",
    "params = {\n",
    "    'objective': 'survival:cox',\n",
    "    'eval_metric': 'cox-nloglik',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=300)\n",
    "\n",
    "# XGBoost Cox produces risk scores as predictions\n",
    "xgb_risk = bst.predict(dtest)\n",
    "cox_cindex = compute_concordance_index(\n",
    "    y_df.loc[X_test.index, 'event'].values,\n",
    "    y_df.loc[X_test.index, 'time_to_event'].values,\n",
    "    xgb_risk,\n",
    ")\n",
    "print(f\"XGBoost Cox C-index (holdout): {cox_cindex:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:50.557504Z",
     "iopub.status.busy": "2025-10-21T08:10:50.557504Z",
     "iopub.status.idle": "2025-10-21T08:10:51.222985Z",
     "shell.execute_reply": "2025-10-21T08:10:51.222527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick AUC (30-day classification proxy): 0.687\n",
      "Top 15 features:\n",
      " lab_51301    0.085971\n",
      "lab_51265    0.078831\n",
      "lab_50983    0.060554\n",
      "lab_51277    0.055757\n",
      "lab_51222    0.053808\n",
      "lab_50931    0.050722\n",
      "lab_51221    0.048176\n",
      "lab_50893    0.044860\n",
      "lab_51249    0.043307\n",
      "lab_51279    0.043026\n",
      "lab_50970    0.040929\n",
      "lab_50902    0.038081\n",
      "lab_51248    0.037272\n",
      "lab_50960    0.036535\n",
      "lab_50912    0.035801\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train/test split and RF model (ensure X_train/X_test defined)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "mask = X.notna().all(axis=1)\n",
    "Xc = X[mask]\n",
    "yc = y[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=0.3, random_state=42, stratify=yc)\n",
    "y_df_train = y_df.loc[X_train.index]\n",
    "y_df_test = y_df.loc[X_test.index]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "print(f'Quick AUC (30-day classification proxy): {auc:.3f}')\n",
    "\n",
    "imp = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print('Top 15 features:\\n', imp.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Model Evaluation\n",
    "\n",
    "Now let's evaluate each model with proper survival analysis metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cox PH Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:51.225996Z",
     "iopub.status.busy": "2025-10-21T08:10:51.225996Z",
     "iopub.status.idle": "2025-10-21T08:10:51.727997Z",
     "shell.execute_reply": "2025-10-21T08:10:51.727043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COX PROPORTIONAL HAZARDS MODEL EVALUATION\n",
      "==================================================\n",
      "C-index: 0.696\n",
      "Interpretation: 69.6% of patient pairs correctly ordered by risk\n",
      "\n",
      "Time-dependent AUC:\n",
      "  Day  1: 0.260\n",
      "  Day  7: 0.625\n",
      "  Day 14: 0.731\n",
      "  Day 21: 0.693\n",
      "Mean AUC: 0.662\n",
      "\n",
      "Integrated Brier Score: 0.080\n",
      "\n",
      "Calibration (5 bins):\n",
      "  Bin 1: Pred=0.062, Obs=0.062, Diff=+0.001\n",
      "  Bin 2: Pred=0.088, Obs=0.062, Diff=-0.025\n",
      "  Bin 3: Pred=0.118, Obs=0.188, Diff=+0.070\n",
      "  Bin 4: Pred=0.156, Obs=0.267, Diff=+0.111\n",
      "  Bin 5: Pred=0.294, Obs=0.400, Diff=+0.106\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Cox PH Evaluation\n",
    "from app.evaluation import compute_concordance_index, compute_td_auc, compute_brier_score, compute_calibration\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"COX PROPORTIONAL HAZARDS MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Basic Performance Metrics\n",
    "print(f\"C-index: {c_index:.3f}\")\n",
    "print(f\"Interpretation: {c_index:.1%} of patient pairs correctly ordered by risk\")\n",
    "\n",
    "# 2. Time-dependent AUC\n",
    "time_horizons = [1, 7, 14, 21]\n",
    "y_train_tuple = (y_df_train['event'].values, y_df_train['time_to_event'].values)\n",
    "y_test_tuple = (y_df_test['event'].values, y_df_test['time_to_event'].values)\n",
    "\n",
    "td_auc, mean_auc = compute_td_auc(y_train_tuple, y_test_tuple, risk_scores, time_horizons)\n",
    "print(f\"\\nTime-dependent AUC:\")\n",
    "for t, auc in zip(time_horizons, td_auc):\n",
    "    print(f\"  Day {t:2d}: {auc:.3f}\")\n",
    "print(f\"Mean AUC: {mean_auc:.3f}\")\n",
    "\n",
    "# 3. Integrated Brier Score\n",
    "cox_test_df = X_test.copy()\n",
    "cox_test_df['time_to_event'] = y_df_test['time_to_event'].values\n",
    "cox_test_df['event'] = y_df_test['event'].values\n",
    "survival_probs = cph.predict_survival_function(cox_test_df, times=time_horizons)\n",
    "survival_probs_matrix = survival_probs.T.values\n",
    "ibs = compute_brier_score(y_train_tuple, y_test_tuple, survival_probs_matrix, time_horizons)\n",
    "print(f\"\\nIntegrated Brier Score: {ibs:.3f}\")\n",
    "\n",
    "# 4. Calibration\n",
    "event_probs_30d = 1 - survival_probs_matrix[:, -1]\n",
    "calibration = compute_calibration(event_probs_30d, y_df_test['event'].values, n_bins=5)\n",
    "print(f\"\\nCalibration (5 bins):\")\n",
    "for i, bin_data in enumerate(calibration['bins']):\n",
    "    diff = bin_data['obs'] - bin_data['pred']\n",
    "    print(f\"  Bin {i+1}: Pred={bin_data['pred']:.3f}, Obs={bin_data['obs']:.3f}, Diff={diff:+.3f}\")\n",
    "\n",
    "# Store Cox results for comparison\n",
    "cox_results = {\n",
    "    'model': 'Cox PH',\n",
    "    'c_index': c_index,\n",
    "    'td_auc_mean': mean_auc,\n",
    "    'ibs': ibs,\n",
    "    'calibration_error': abs(calibration['bins'][-1]['obs'] - calibration['bins'][-1]['pred'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Survival Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:51.732244Z",
     "iopub.status.busy": "2025-10-21T08:10:51.731238Z",
     "iopub.status.idle": "2025-10-21T08:10:51.753147Z",
     "shell.execute_reply": "2025-10-21T08:10:51.753147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBOOST SURVIVAL MODEL EVALUATION\n",
      "==================================================\n",
      "C-index: 0.622\n",
      "\n",
      "Time-dependent AUC:\n",
      "  Day  1: 0.468\n",
      "  Day  7: 0.652\n",
      "  Day 14: 0.629\n",
      "  Day 21: 0.575\n",
      "Mean AUC: 0.610\n",
      "\n",
      "Integrated Brier Score: 0.907\n",
      "\n",
      "Calibration (5 bins):\n",
      "  Bin 1: Pred=1.000, Obs=0.250, Diff=-0.750\n",
      "  Bin 2: Pred=1.000, Obs=0.188, Diff=-0.812\n",
      "  Bin 3: Pred=1.000, Obs=0.125, Diff=-0.875\n",
      "  Bin 4: Pred=1.000, Obs=0.133, Diff=-0.867\n",
      "  Bin 5: Pred=1.000, Obs=0.267, Diff=-0.733\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive XGBoost Evaluation\n",
    "print(\"\\nXGBOOST SURVIVAL MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# XGBoost already trained above, get predictions\n",
    "xgb_risk = bst.predict(dtest)\n",
    "xgb_c_index = compute_concordance_index(\n",
    "    y_df_test['event'].values,\n",
    "    y_df_test['time_to_event'].values,\n",
    "    xgb_risk\n",
    ")\n",
    "\n",
    "print(f\"C-index: {xgb_c_index:.3f}\")\n",
    "\n",
    "# Time-dependent AUC for XGBoost\n",
    "xgb_td_auc, xgb_mean_auc = compute_td_auc(y_train_tuple, y_test_tuple, xgb_risk, time_horizons)\n",
    "print(f\"\\nTime-dependent AUC:\")\n",
    "for t, auc in zip(time_horizons, xgb_td_auc):\n",
    "    print(f\"  Day {t:2d}: {auc:.3f}\")\n",
    "print(f\"Mean AUC: {xgb_mean_auc:.3f}\")\n",
    "\n",
    "# For XGBoost, we need to approximate survival probabilities\n",
    "# This is a simplified approach - in practice, you'd use proper survival probability estimation\n",
    "xgb_survival_probs = np.exp(-xgb_risk.reshape(-1, 1) * np.array(time_horizons).reshape(1, -1))\n",
    "xgb_ibs = compute_brier_score(y_train_tuple, y_test_tuple, xgb_survival_probs, time_horizons)\n",
    "print(f\"\\nIntegrated Brier Score: {xgb_ibs:.3f}\")\n",
    "\n",
    "# Calibration for XGBoost\n",
    "xgb_event_probs_30d = 1 - xgb_survival_probs[:, -1]\n",
    "xgb_calibration = compute_calibration(xgb_event_probs_30d, y_df_test['event'].values, n_bins=5)\n",
    "print(f\"\\nCalibration (5 bins):\")\n",
    "for i, bin_data in enumerate(xgb_calibration['bins']):\n",
    "    diff = bin_data['obs'] - bin_data['pred']\n",
    "    print(f\"  Bin {i+1}: Pred={bin_data['pred']:.3f}, Obs={bin_data['obs']:.3f}, Diff={diff:+.3f}\")\n",
    "\n",
    "# Store XGBoost results\n",
    "xgb_results = {\n",
    "    'model': 'XGBoost Cox',\n",
    "    'c_index': xgb_c_index,\n",
    "    'td_auc_mean': xgb_mean_auc,\n",
    "    'ibs': xgb_ibs,\n",
    "    'calibration_error': abs(xgb_calibration['bins'][-1]['obs'] - xgb_calibration['bins'][-1]['pred'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:51.757154Z",
     "iopub.status.busy": "2025-10-21T08:10:51.757154Z",
     "iopub.status.idle": "2025-10-21T08:10:51.778393Z",
     "shell.execute_reply": "2025-10-21T08:10:51.778393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL COMPARISON SUMMARY\n",
      "==================================================\n",
      "         model  c_index  td_auc_mean    ibs  calibration_error\n",
      "0       Cox PH    0.696        0.662  0.080              0.106\n",
      "1  XGBoost Cox    0.622        0.610  0.907              0.733\n",
      "\n",
      "ðŸ† BEST PERFORMING MODEL:\n",
      "  â€¢ Best C-index: Cox PH\n",
      "  â€¢ Best IBS (calibration): Cox PH\n",
      "  â€¢ Best calibration: Cox PH\n",
      "\n",
      "ðŸ“Š PERFORMANCE RANKINGS:\n",
      "C-index ranking:\n",
      "  1. Cox PH: 0.696\n",
      "  2. XGBoost Cox: 0.622\n",
      "\n",
      "IBS ranking (lower is better):\n",
      "  1. Cox PH: 0.080\n",
      "  2. XGBoost Cox: 0.907\n",
      "\n",
      "âœ… RECOMMENDATION:\n",
      "  Cox PH model shows better discrimination (0.696 vs 0.622)\n",
      "  Cox PH is more interpretable with hazard ratios\n",
      "  Recommended for clinical use: Cox PH\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame([cox_results, xgb_results])\n",
    "print(\"\\nMODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(results_df.round(3))\n",
    "\n",
    "print(f\"\\nðŸ† BEST PERFORMING MODEL:\")\n",
    "best_c_index = results_df.loc[results_df['c_index'].idxmax(), 'model']\n",
    "best_ibs = results_df.loc[results_df['ibs'].idxmin(), 'model']\n",
    "best_calibration = results_df.loc[results_df['calibration_error'].idxmin(), 'model']\n",
    "\n",
    "print(f\"  â€¢ Best C-index: {best_c_index}\")\n",
    "print(f\"  â€¢ Best IBS (calibration): {best_ibs}\")\n",
    "print(f\"  â€¢ Best calibration: {best_calibration}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š PERFORMANCE RANKINGS:\")\n",
    "print(\"C-index ranking:\")\n",
    "for i, (_, row) in enumerate(results_df.sort_values('c_index', ascending=False).iterrows()):\n",
    "    print(f\"  {i+1}. {row['model']}: {row['c_index']:.3f}\")\n",
    "\n",
    "print(\"\\nIBS ranking (lower is better):\")\n",
    "for i, (_, row) in enumerate(results_df.sort_values('ibs').iterrows()):\n",
    "    print(f\"  {i+1}. {row['model']}: {row['ibs']:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ… RECOMMENDATION:\")\n",
    "if cox_results['c_index'] > xgb_results['c_index']:\n",
    "    print(f\"  Cox PH model shows better discrimination ({cox_results['c_index']:.3f} vs {xgb_results['c_index']:.3f})\")\n",
    "    print(f\"  Cox PH is more interpretable with hazard ratios\")\n",
    "    print(f\"  Recommended for clinical use: Cox PH\")\n",
    "else:\n",
    "    print(f\"  XGBoost shows better discrimination ({xgb_results['c_index']:.3f} vs {cox_results['c_index']:.3f})\")\n",
    "    print(f\"  XGBoost captures non-linear relationships\")\n",
    "    print(f\"  Consider ensemble or Cox PH for interpretability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:51.787582Z",
     "iopub.status.busy": "2025-10-21T08:10:51.786583Z",
     "iopub.status.idle": "2025-10-21T08:10:52.191945Z",
     "shell.execute_reply": "2025-10-21T08:10:52.190930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (260, 40)\n",
      "Num lab-derived columns: 0\n"
     ]
    }
   ],
   "source": [
    "# Build features via app.feature_engineering (includes labs when available)\n",
    "from app.feature_engineering import engineer_features\n",
    "\n",
    "X, y_df = engineer_features(cohort)\n",
    "y = y_df['event'].astype(int)\n",
    "\n",
    "print('Feature matrix shape:', X.shape)\n",
    "print('Num lab-derived columns:', sum(col.startswith('\"lab_\"') for col in X.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T08:10:52.194942Z",
     "iopub.status.busy": "2025-10-21T08:10:52.194039Z",
     "iopub.status.idle": "2025-10-21T08:10:52.839450Z",
     "shell.execute_reply": "2025-10-21T08:10:52.839450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick AUC (30-day classification proxy): 0.576\n",
      "Top 15 features:\n",
      " age_at_discharge                                   0.401644\n",
      "gender_M                                           0.081105\n",
      "discharge_location_SKILLED NURSING FACILITY        0.060272\n",
      "insurance_Medicare                                 0.050945\n",
      "insurance_Other                                    0.050063\n",
      "admission_type_EW EMER.                            0.049381\n",
      "discharge_location_HOME                            0.048827\n",
      "admission_type_DIRECT EMER.                        0.038194\n",
      "discharge_location_HOME HEALTH CARE                0.034777\n",
      "admission_type_OBSERVATION ADMIT                   0.031774\n",
      "admission_type_URGENT                              0.028284\n",
      "discharge_location_REHAB                           0.024051\n",
      "discharge_location_CHRONIC/LONG TERM ACUTE CARE    0.022864\n",
      "admission_type_SURGICAL SAME DAY ADMISSION         0.020727\n",
      "admission_type_EU OBSERVATION                      0.013956\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load cohort from previous step\n",
    "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n",
    "\n",
    "# Basic numeric/categorical feature set for quick pass\n",
    "X_cols = []\n",
    "for c in ['age_at_discharge','los_days']:\n",
    "    if c in cohort.columns:\n",
    "        X_cols.append(c)\n",
    "\n",
    "# One-hot encode a few categoricals\n",
    "cat_cols = [c for c in ['gender','admission_type','discharge_location','insurance'] if c in cohort.columns]\n",
    "X = pd.get_dummies(cohort[X_cols + cat_cols], drop_first=True)\n",
    "y = cohort['event'].astype(int)\n",
    "\n",
    "# Drop rows with any NA in features\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# AUC as quick heuristic\n",
    "proba = clf.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "print(f\"Quick AUC (30-day classification proxy): {auc:.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "imp = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Top 15 features:\\n\", imp.head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
