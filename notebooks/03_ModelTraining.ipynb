{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: C:\\Users\\Golds\\Downloads\\survival-readmission\n"
          ]
        }
      ],
      "source": [
        "# Ensure repository root on sys.path for `import app.*`\n",
        "import sys\n",
        "from pathlib import Path\n",
        "repo_root = (Path.cwd() / '..').resolve()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Repo root:', repo_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Model Training and Evaluation\n",
        "\n",
        "This notebook trains multiple survival models and calculates performance metrics:\n",
        "- Cox Proportional Hazards\n",
        "- XGBoost Survival (Cox objective)\n",
        "- XGBoost Survival (AFT objective)\n",
        "- Random Forest (classification proxy)\n",
        "- C-index and other performance metrics for each model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sksurv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlifelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoxPHFitter\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_concordance_index, compute_td_auc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\survival-readmission\\app\\evaluation.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterable, Tuple\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msksurv\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     concordance_index_censored,\n\u001b[32m     15\u001b[39m     cumulative_dynamic_auc,\n\u001b[32m     16\u001b[39m     integrated_brier_score,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_concordance_index\u001b[39m(event: Iterable[\u001b[38;5;28mint\u001b[39m], time: Iterable[\u001b[38;5;28mfloat\u001b[39m], risk_scores: Iterable[\u001b[38;5;28mfloat\u001b[39m]) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute Harrell's C-index.\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[33;03m        C-index in [0, 1].\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sksurv'"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from lifelines import CoxPHFitter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "from app.evaluation import compute_concordance_index, compute_td_auc\n",
        "from app.feature_engineering import engineer_features\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Prepare Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cohort and build features\n",
        "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n",
        "\n",
        "# Build features via app.feature_engineering (includes labs when available)\n",
        "import os\n",
        "os.environ['MIMIC_DEMO_DIR'] = '../data/raw/mimic-iv-demo'\n",
        "\n",
        "X, y_df = engineer_features(cohort)\n",
        "\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Num lab-derived columns:', sum([1 for col in X.columns if str(col).startswith('lab_')]))\n",
        "print('Sample lab columns:', [col for col in X.columns if str(col).startswith('lab_')][:5])\n",
        "print(f\"Event rate: {y_df['event'].mean():.3f}\")\n",
        "print(f\"Mean time to event: {y_df['time_to_event'].mean():.1f} days\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_df, test_size=0.3, random_state=42, stratify=y_df['event']\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Event rate in train: {y_train['event'].mean():.3f}\")\n",
        "print(f\"Event rate in test: {y_test['event'].mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Multiple Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Cox Proportional Hazards\n",
        "print(\"Training Cox Proportional Hazards...\")\n",
        "cox_train = X_train.copy()\n",
        "cox_train['time_to_event'] = y_train['time_to_event'].values\n",
        "cox_train['event'] = y_train['event'].values\n",
        "\n",
        "cox_test = X_test.copy()\n",
        "cox_test['time_to_event'] = y_test['time_to_event'].values\n",
        "cox_test['event'] = y_test['event'].values\n",
        "\n",
        "cph = CoxPHFitter(penalizer=0.1, l1_ratio=0.1)\n",
        "cph.fit(cox_train, duration_col='time_to_event', event_col='event', show_progress=False)\n",
        "cox_risk_scores = cph.predict_partial_hazard(cox_test)\n",
        "print(\"âœ“ Cox PH trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. XGBoost Survival (Cox objective)\n",
        "print(\"Training XGBoost Survival (Cox)...\")\n",
        "dtrain_cox = xgb.DMatrix(X_train, label=y_train['time_to_event'].values)\n",
        "dtest_cox = xgb.DMatrix(X_test, label=y_test['time_to_event'].values)\n",
        "\n",
        "params_cox = {\n",
        "    'objective': 'survival:cox',\n",
        "    'eval_metric': 'cox-nloglik',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 3,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "xgb_cox = xgb.train(params_cox, dtrain_cox, num_boost_round=300, verbose_eval=False)\n",
        "xgb_cox_risk_scores = xgb_cox.predict(dtest_cox)\n",
        "print(\"âœ“ XGBoost Cox trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. XGBoost Survival (AFT objective)\n",
        "print(\"Training XGBoost Survival (AFT)...\")\n",
        "dtrain_aft = xgb.DMatrix(X_train, label=y_train['time_to_event'].values)\n",
        "dtest_aft = xgb.DMatrix(X_test, label=y_test['time_to_event'].values)\n",
        "\n",
        "params_aft = {\n",
        "    'objective': 'survival:aft',\n",
        "    'eval_metric': 'aft-nloglik',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 3,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "xgb_aft = xgb.train(params_aft, dtrain_aft, num_boost_round=300, verbose_eval=False)\n",
        "xgb_aft_risk_scores = xgb_aft.predict(dtest_aft)\n",
        "print(\"âœ“ XGBoost AFT trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Random Forest (classification proxy)\n",
        "print(\"Training Random Forest...\")\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train['event'])\n",
        "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
        "print(\"âœ“ Random Forest trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute C-index for all models\n",
        "models = {\n",
        "    'Cox PH': cox_risk_scores,\n",
        "    'XGBoost Cox': xgb_cox_risk_scores,\n",
        "    'XGBoost AFT': xgb_aft_risk_scores,\n",
        "    'Random Forest': rf_proba\n",
        "}\n",
        "\n",
        "c_indices = {}\n",
        "for name, scores in models.items():\n",
        "    c_index = compute_concordance_index(y_test['event'], y_test['time_to_event'], scores)\n",
        "    c_indices[name] = c_index\n",
        "    print(f\"{name} C-index: {c_index:.3f}\")\n",
        "\n",
        "# Create comparison table\n",
        "comparison_df = pd.DataFrame([\n",
        "    {'Model': name, 'C-index': c_index}\n",
        "    for name, c_index in c_indices.items()\n",
        "]).sort_values('C-index', ascending=False)\n",
        "\n",
        "print(\"\\nModel Performance Ranking:\")\n",
        "print(comparison_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model results for use in other notebooks\n",
        "model_results = {\n",
        "    'models': models,\n",
        "    'c_indices': c_indices,\n",
        "    'comparison_df': comparison_df,\n",
        "    'X_test': X_test,\n",
        "    'y_test': y_test,\n",
        "    'cph': cph,\n",
        "    'xgb_cox': xgb_cox,\n",
        "    'xgb_aft': xgb_aft,\n",
        "    'rf': rf\n",
        "}\n",
        "\n",
        "# Save to pickle for use in other notebooks\n",
        "import pickle\n",
        "with open('../models/model_results.pkl', 'wb') as f:\n",
        "    pickle.dump(model_results, f)\n",
        "\n",
        "print(\"Model results saved to ../models/model_results.pkl\")\n",
        "print(\"This data will be used in notebooks 05 and 06 for comparison and interpretability analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cohort from previous step (ensure variable exists before feature engineering)\n",
        "import pandas as pd\n",
        "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix shape: (260, 20)\n",
            "Num lab-derived columns: 0\n"
          ]
        }
      ],
      "source": [
        "# Build features via app.feature_engineering (includes labs when available)\n",
        "from app.feature_engineering import engineer_features\n",
        "\n",
        "X, y_df = engineer_features(cohort)\n",
        "y = y_df['event'].astype(int)\n",
        "\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Num lab-derived columns:', sum([1 for col in X.columns if str(col).startswith('lab_')]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: C:\\Users\\Golds\\Downloads\\survival-readmission\n"
          ]
        }
      ],
      "source": [
        "# Setup: add repo root to path for `app.*`\n",
        "import sys\n",
        "from pathlib import Path\n",
        "repo_root = (Path.cwd() / '..').resolve()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Repo root:', repo_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cox Proportional Hazards (baseline)\n",
        "Fit an interpretable Cox PH model and report C-index on a holdout split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Cox PH\n",
        "from lifelines import CoxPHFitter\n",
        "from app.evaluation import compute_concordance_index\n",
        "\n",
        "cox_df = X.copy()\n",
        "cox_df[\"time_to_event\"] = y_df[\"time_to_event\"].values\n",
        "cox_df[\"event\"] = y_df[\"event\"].values\n",
        "\n",
        "# Simple train/test split by index (for demo; prefer temporal split in practice)\n",
        "train_idx, test_idx = X_train.index, X_test.index\n",
        "cox_train = cox_df.loc[train_idx]\n",
        "cox_test = cox_df.loc[test_idx]\n",
        "\n",
        "cph = CoxPHFitter(penalizer=0.1, l1_ratio=0.1)\n",
        "cph.fit(cox_train.assign(event=cox_train[\"event\"].astype(bool)), duration_col=\"time_to_event\", event_col=\"event\", show_progress=False)\n",
        "\n",
        "# Risk scores and C-index\n",
        "risk_scores = cph.predict_partial_hazard(cox_test)\n",
        "c_index = compute_concordance_index(cox_test[\"event\"], cox_test[\"time_to_event\"], risk_scores)\n",
        "print(f\"Cox PH C-index (holdout): {c_index:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost Survival (Cox objective)\n",
        "Train an XGBoost model with survival:cox to produce risk scores and compute C-index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Prepare DMatrix for XGBoost Cox\n",
        "# For Cox, label is time; event is provided implicitly via order weighting\n",
        "# We'll follow the typical approach: sort by time and pass (time, event) via special settings.\n",
        "\n",
        "# Create DMatrix with features\n",
        "dtrain = xgb.DMatrix(X_train, label=y_df.loc[X_train.index, 'time_to_event'].values)\n",
        "dtest = xgb.DMatrix(X_test, label=y_df.loc[X_test.index, 'time_to_event'].values)\n",
        "\n",
        "params = {\n",
        "    'objective': 'survival:cox',\n",
        "    'eval_metric': 'cox-nloglik',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 3,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "bst = xgb.train(params, dtrain, num_boost_round=300)\n",
        "\n",
        "# XGBoost Cox produces risk scores as predictions\n",
        "xgb_risk = bst.predict(dtest)\n",
        "cox_cindex = compute_concordance_index(\n",
        "    y_df.loc[X_test.index, 'event'].values,\n",
        "    y_df.loc[X_test.index, 'time_to_event'].values,\n",
        "    xgb_risk,\n",
        ")\n",
        "print(f\"XGBoost Cox C-index (holdout): {cox_cindex:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split and RF model (ensure X_train/X_test defined)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "mask = X.notna().all(axis=1)\n",
        "Xc = X[mask]\n",
        "yc = y[mask]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=0.3, random_state=42, stratify=yc)\n",
        "y_df_train = y_df.loc[X_train.index]\n",
        "y_df_test = y_df.loc[X_test.index]\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n",
        "proba = clf.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "print(f'Quick AUC (30-day classification proxy): {auc:.3f}')\n",
        "\n",
        "imp = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "print('Top 15 features:\\n', imp.head(15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comprehensive Model Evaluation\n",
        "\n",
        "Now let's evaluate each model with proper survival analysis metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cox PH Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Cox PH Evaluation\n",
        "from app.evaluation import compute_concordance_index, compute_td_auc, compute_brier_score, compute_calibration\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"COX PROPORTIONAL HAZARDS MODEL EVALUATION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Basic Performance Metrics\n",
        "print(f\"C-index: {c_index:.3f}\")\n",
        "print(f\"Interpretation: {c_index:.1%} of patient pairs correctly ordered by risk\")\n",
        "\n",
        "# 2. Time-dependent AUC\n",
        "time_horizons = [1, 7, 14, 21]\n",
        "y_train_tuple = (y_df_train['event'].values, y_df_train['time_to_event'].values)\n",
        "y_test_tuple = (y_df_test['event'].values, y_df_test['time_to_event'].values)\n",
        "\n",
        "td_auc, mean_auc = compute_td_auc(y_train_tuple, y_test_tuple, risk_scores, time_horizons)\n",
        "print(f\"\\nTime-dependent AUC:\")\n",
        "for t, auc in zip(time_horizons, td_auc):\n",
        "    print(f\"  Day {t:2d}: {auc:.3f}\")\n",
        "print(f\"Mean AUC: {mean_auc:.3f}\")\n",
        "\n",
        "# 3. Integrated Brier Score\n",
        "cox_test_df = X_test.copy()\n",
        "cox_test_df['time_to_event'] = y_df_test['time_to_event'].values\n",
        "cox_test_df['event'] = y_df_test['event'].values\n",
        "survival_probs = cph.predict_survival_function(cox_test_df, times=time_horizons)\n",
        "survival_probs_matrix = survival_probs.T.values\n",
        "ibs = compute_brier_score(y_train_tuple, y_test_tuple, survival_probs_matrix, time_horizons)\n",
        "print(f\"\\nIntegrated Brier Score: {ibs:.3f}\")\n",
        "\n",
        "# 4. Calibration\n",
        "event_probs_30d = 1 - survival_probs_matrix[:, -1]\n",
        "calibration = compute_calibration(event_probs_30d, y_df_test['event'].values, n_bins=5)\n",
        "print(f\"\\nCalibration (5 bins):\")\n",
        "for i, bin_data in enumerate(calibration['bins']):\n",
        "    diff = bin_data['obs'] - bin_data['pred']\n",
        "    print(f\"  Bin {i+1}: Pred={bin_data['pred']:.3f}, Obs={bin_data['obs']:.3f}, Diff={diff:+.3f}\")\n",
        "\n",
        "# Store Cox results for comparison\n",
        "cox_results = {\n",
        "    'model': 'Cox PH',\n",
        "    'c_index': c_index,\n",
        "    'td_auc_mean': mean_auc,\n",
        "    'ibs': ibs,\n",
        "    'calibration_error': abs(calibration['bins'][-1]['obs'] - calibration['bins'][-1]['pred'])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost Survival Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive XGBoost Evaluation\n",
        "print(\"\\nXGBOOST SURVIVAL MODEL EVALUATION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# XGBoost already trained above, get predictions\n",
        "xgb_risk = bst.predict(dtest)\n",
        "xgb_c_index = compute_concordance_index(\n",
        "    y_df_test['event'].values,\n",
        "    y_df_test['time_to_event'].values,\n",
        "    xgb_risk\n",
        ")\n",
        "\n",
        "print(f\"C-index: {xgb_c_index:.3f}\")\n",
        "\n",
        "# Time-dependent AUC for XGBoost\n",
        "xgb_td_auc, xgb_mean_auc = compute_td_auc(y_train_tuple, y_test_tuple, xgb_risk, time_horizons)\n",
        "print(f\"\\nTime-dependent AUC:\")\n",
        "for t, auc in zip(time_horizons, xgb_td_auc):\n",
        "    print(f\"  Day {t:2d}: {auc:.3f}\")\n",
        "print(f\"Mean AUC: {xgb_mean_auc:.3f}\")\n",
        "\n",
        "# For XGBoost, we need to approximate survival probabilities\n",
        "# This is a simplified approach - in practice, you'd use proper survival probability estimation\n",
        "xgb_survival_probs = np.exp(-xgb_risk.reshape(-1, 1) * np.array(time_horizons).reshape(1, -1))\n",
        "xgb_ibs = compute_brier_score(y_train_tuple, y_test_tuple, xgb_survival_probs, time_horizons)\n",
        "print(f\"\\nIntegrated Brier Score: {xgb_ibs:.3f}\")\n",
        "\n",
        "# Calibration for XGBoost\n",
        "xgb_event_probs_30d = 1 - xgb_survival_probs[:, -1]\n",
        "xgb_calibration = compute_calibration(xgb_event_probs_30d, y_df_test['event'].values, n_bins=5)\n",
        "print(f\"\\nCalibration (5 bins):\")\n",
        "for i, bin_data in enumerate(xgb_calibration['bins']):\n",
        "    diff = bin_data['obs'] - bin_data['pred']\n",
        "    print(f\"  Bin {i+1}: Pred={bin_data['pred']:.3f}, Obs={bin_data['obs']:.3f}, Diff={diff:+.3f}\")\n",
        "\n",
        "# Store XGBoost results\n",
        "xgb_results = {\n",
        "    'model': 'XGBoost Cox',\n",
        "    'c_index': xgb_c_index,\n",
        "    'td_auc_mean': xgb_mean_auc,\n",
        "    'ibs': xgb_ibs,\n",
        "    'calibration_error': abs(xgb_calibration['bins'][-1]['obs'] - xgb_calibration['bins'][-1]['pred'])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Comparison Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame([cox_results, xgb_results])\n",
        "print(\"\\nMODEL COMPARISON SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(results_df.round(3))\n",
        "\n",
        "print(f\"\\nðŸ† BEST PERFORMING MODEL:\")\n",
        "best_c_index = results_df.loc[results_df['c_index'].idxmax(), 'model']\n",
        "best_ibs = results_df.loc[results_df['ibs'].idxmin(), 'model']\n",
        "best_calibration = results_df.loc[results_df['calibration_error'].idxmin(), 'model']\n",
        "\n",
        "print(f\"  â€¢ Best C-index: {best_c_index}\")\n",
        "print(f\"  â€¢ Best IBS (calibration): {best_ibs}\")\n",
        "print(f\"  â€¢ Best calibration: {best_calibration}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š PERFORMANCE RANKINGS:\")\n",
        "print(\"C-index ranking:\")\n",
        "for i, (_, row) in enumerate(results_df.sort_values('c_index', ascending=False).iterrows()):\n",
        "    print(f\"  {i+1}. {row['model']}: {row['c_index']:.3f}\")\n",
        "\n",
        "print(\"\\nIBS ranking (lower is better):\")\n",
        "for i, (_, row) in enumerate(results_df.sort_values('ibs').iterrows()):\n",
        "    print(f\"  {i+1}. {row['model']}: {row['ibs']:.3f}\")\n",
        "\n",
        "print(f\"\\nâœ… RECOMMENDATION:\")\n",
        "if cox_results['c_index'] > xgb_results['c_index']:\n",
        "    print(f\"  Cox PH model shows better discrimination ({cox_results['c_index']:.3f} vs {xgb_results['c_index']:.3f})\")\n",
        "    print(f\"  Cox PH is more interpretable with hazard ratios\")\n",
        "    print(f\"  Recommended for clinical use: Cox PH\")\n",
        "else:\n",
        "    print(f\"  XGBoost shows better discrimination ({xgb_results['c_index']:.3f} vs {cox_results['c_index']:.3f})\")\n",
        "    print(f\"  XGBoost captures non-linear relationships\")\n",
        "    print(f\"  Consider ensemble or Cox PH for interpretability\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build features via app.feature_engineering (includes labs when available)\n",
        "from app.feature_engineering import engineer_features\n",
        "\n",
        "X, y_df = engineer_features(cohort)\n",
        "y = y_df['event'].astype(int)\n",
        "\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Num lab-derived columns:', sum(col.startswith('\"lab_\"') for col in X.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quick AUC (30-day classification proxy): 0.576\n",
            "Top 15 features:\n",
            " age_at_discharge                                   0.401644\n",
            "gender_M                                           0.081105\n",
            "discharge_location_SKILLED NURSING FACILITY        0.060272\n",
            "insurance_Medicare                                 0.050945\n",
            "insurance_Other                                    0.050063\n",
            "admission_type_EW EMER.                            0.049381\n",
            "discharge_location_HOME                            0.048827\n",
            "admission_type_DIRECT EMER.                        0.038194\n",
            "discharge_location_HOME HEALTH CARE                0.034777\n",
            "admission_type_OBSERVATION ADMIT                   0.031774\n",
            "admission_type_URGENT                              0.028284\n",
            "discharge_location_REHAB                           0.024051\n",
            "discharge_location_CHRONIC/LONG TERM ACUTE CARE    0.022864\n",
            "admission_type_SURGICAL SAME DAY ADMISSION         0.020727\n",
            "admission_type_EU OBSERVATION                      0.013956\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load cohort from previous step\n",
        "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n",
        "\n",
        "# Basic numeric/categorical feature set for quick pass\n",
        "X_cols = []\n",
        "for c in ['age_at_discharge','los_days']:\n",
        "    if c in cohort.columns:\n",
        "        X_cols.append(c)\n",
        "\n",
        "# One-hot encode a few categoricals\n",
        "cat_cols = [c for c in ['gender','admission_type','discharge_location','insurance'] if c in cohort.columns]\n",
        "X = pd.get_dummies(cohort[X_cols + cat_cols], drop_first=True)\n",
        "y = cohort['event'].astype(int)\n",
        "\n",
        "# Drop rows with any NA in features\n",
        "mask = X.notna().all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# AUC as quick heuristic\n",
        "proba = clf.predict_proba(X_test)[:,1]\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "print(f\"Quick AUC (30-day classification proxy): {auc:.3f}\")\n",
        "\n",
        "# Feature importance\n",
        "imp = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"Top 15 features:\\n\", imp.head(15))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
