{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05 - Model Comparison Dashboard\n",
        "\n",
        "This notebook provides an easy comparison of all models trained in notebook 3:\n",
        "- Loads model results from notebook 3\n",
        "- Side-by-side performance comparison\n",
        "- Visual comparison of model outputs\n",
        "- Clinical decision support metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure repository root on sys.path for `import app.*`\n",
        "import sys\n",
        "from pathlib import Path\n",
        "repo_root = (Path.cwd() / '..').resolve()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Repo root:', repo_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from lifelines import CoxPHFitter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "from app.evaluation import compute_concordance_index, compute_td_auc\n",
        "from app.feature_engineering import engineer_features\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model results from notebook 3\n",
        "import pickle\n",
        "with open('../models/model_results.pkl', 'rb') as f:\n",
        "    model_results = pickle.load(f)\n",
        "\n",
        "# Extract data\n",
        "models = model_results['models']\n",
        "c_indices = model_results['c_indices']\n",
        "comparison_df = model_results['comparison_df']\n",
        "X_test = model_results['X_test']\n",
        "y_test = model_results['y_test']\n",
        "\n",
        "print(\"Model results loaded successfully!\")\n",
        "print(f\"Available models: {list(models.keys())}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Event rate: {y_test['event'].mean():.3f}\")\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "print(comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Multiple Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Cox Proportional Hazards\n",
        "print(\"Training Cox Proportional Hazards...\")\n",
        "cox_train = X_train.copy()\n",
        "cox_train['time_to_event'] = y_train['time_to_event'].values\n",
        "cox_train['event'] = y_train['event'].values\n",
        "\n",
        "cox_test = X_test.copy()\n",
        "cox_test['time_to_event'] = y_test['time_to_event'].values\n",
        "cox_test['event'] = y_test['event'].values\n",
        "\n",
        "cph = CoxPHFitter(penalizer=0.1, l1_ratio=0.1)\n",
        "cph.fit(cox_train, duration_col='time_to_event', event_col='event', show_progress=False)\n",
        "cox_risk_scores = cph.predict_partial_hazard(cox_test)\n",
        "print(\"✓ Cox PH trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. XGBoost Survival (Cox objective)\n",
        "print(\"Training XGBoost Survival (Cox)...\")\n",
        "dtrain_cox = xgb.DMatrix(X_train, label=y_train['time_to_event'].values)\n",
        "dtest_cox = xgb.DMatrix(X_test, label=y_test['time_to_event'].values)\n",
        "\n",
        "params_cox = {\n",
        "    'objective': 'survival:cox',\n",
        "    'eval_metric': 'cox-nloglik',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 3,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "xgb_cox = xgb.train(params_cox, dtrain_cox, num_boost_round=300, verbose_eval=False)\n",
        "xgb_cox_risk_scores = xgb_cox.predict(dtest_cox)\n",
        "print(\"✓ XGBoost Cox trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. XGBoost Survival (AFT objective)\n",
        "print(\"Training XGBoost Survival (AFT)...\")\n",
        "dtrain_aft = xgb.DMatrix(X_train, label=y_train['time_to_event'].values)\n",
        "dtest_aft = xgb.DMatrix(X_test, label=y_test['time_to_event'].values)\n",
        "\n",
        "params_aft = {\n",
        "    'objective': 'survival:aft',\n",
        "    'eval_metric': 'aft-nloglik',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 3,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "xgb_aft = xgb.train(params_aft, dtrain_aft, num_boost_round=300, verbose_eval=False)\n",
        "xgb_aft_risk_scores = xgb_aft.predict(dtest_aft)\n",
        "print(\"✓ XGBoost AFT trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Random Forest (classification proxy)\n",
        "print(\"Training Random Forest...\")\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train['event'])\n",
        "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
        "print(\"✓ Random Forest trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute C-index for all models\n",
        "models = {\n",
        "    'Cox PH': cox_risk_scores,\n",
        "    'XGBoost Cox': xgb_cox_risk_scores,\n",
        "    'XGBoost AFT': xgb_aft_risk_scores,\n",
        "    'Random Forest': rf_proba\n",
        "}\n",
        "\n",
        "c_indices = {}\n",
        "for name, scores in models.items():\n",
        "    c_index = compute_concordance_index(y_test['event'], y_test['time_to_event'], scores)\n",
        "    c_indices[name] = c_index\n",
        "    print(f\"{name} C-index: {c_index:.3f}\")\n",
        "\n",
        "# Create comparison table\n",
        "comparison_df = pd.DataFrame([\n",
        "    {'Model': name, 'C-index': c_index}\n",
        "    for name, c_index in c_indices.items()\n",
        "]).sort_values('C-index', ascending=False)\n",
        "\n",
        "print(\"\\nModel Performance Ranking:\")\n",
        "print(comparison_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# C-index comparison\n",
        "axes[0, 0].bar(comparison_df['Model'], comparison_df['C-index'], color='steelblue', alpha=0.7)\n",
        "axes[0, 0].set_title('C-index Comparison')\n",
        "axes[0, 0].set_ylabel('C-index')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Risk score distributions\n",
        "axes[0, 1].hist(cox_risk_scores, bins=20, alpha=0.7, label='Cox PH', density=True)\n",
        "axes[0, 1].hist(xgb_cox_risk_scores, bins=20, alpha=0.7, label='XGBoost Cox', density=True)\n",
        "axes[0, 1].hist(xgb_aft_risk_scores, bins=20, alpha=0.7, label='XGBoost AFT', density=True)\n",
        "axes[0, 1].hist(rf_proba, bins=20, alpha=0.7, label='Random Forest', density=True)\n",
        "axes[0, 1].set_title('Risk Score Distributions')\n",
        "axes[0, 1].set_xlabel('Risk Score')\n",
        "axes[0, 1].set_ylabel('Density')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Time-dependent AUC comparison\n",
        "time_points = np.linspace(1, 30, 10)\n",
        "td_auc_results = {}\n",
        "\n",
        "for name, scores in models.items():\n",
        "    td_auc_scores = []\n",
        "    for t in time_points:\n",
        "        auc_t = compute_td_auc(y_test['event'], y_test['time_to_event'], scores, t)\n",
        "        td_auc_scores.append(auc_t)\n",
        "    td_auc_results[name] = td_auc_scores\n",
        "\n",
        "for name, scores in td_auc_results.items():\n",
        "    axes[1, 0].plot(time_points, scores, 'o-', label=name, linewidth=2, markersize=4)\n",
        "\n",
        "axes[1, 0].axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Random')\n",
        "axes[1, 0].set_title('Time-Dependent AUC')\n",
        "axes[1, 0].set_xlabel('Time (days)')\n",
        "axes[1, 0].set_ylabel('AUC')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Model correlation matrix\n",
        "risk_scores_df = pd.DataFrame({\n",
        "    'Cox PH': cox_risk_scores,\n",
        "    'XGBoost Cox': xgb_cox_risk_scores,\n",
        "    'XGBoost AFT': xgb_aft_risk_scores,\n",
        "    'Random Forest': rf_proba\n",
        "})\n",
        "\n",
        "correlation_matrix = risk_scores_df.corr()\n",
        "im = axes[1, 1].imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "axes[1, 1].set_title('Model Correlation Matrix')\n",
        "axes[1, 1].set_xticks(range(len(correlation_matrix.columns)))\n",
        "axes[1, 1].set_yticks(range(len(correlation_matrix.columns)))\n",
        "axes[1, 1].set_xticklabels(correlation_matrix.columns, rotation=45)\n",
        "axes[1, 1].set_yticklabels(correlation_matrix.columns)\n",
        "\n",
        "# Add correlation values to the plot\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(len(correlation_matrix.columns)):\n",
        "        text = axes[1, 1].text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',\n",
        "                              ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
        "\n",
        "plt.colorbar(im, ax=axes[1, 1])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
