{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: C:\\Users\\Golds\\Downloads\\survival-readmission\n"
          ]
        }
      ],
      "source": [
        "# Ensure repository root on sys.path for `import app.*`\n",
        "import sys\n",
        "from pathlib import Path\n",
        "repo_root = (Path.cwd() / '..').resolve()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Repo root:', repo_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Survival Modeling\n",
        "\n",
        "This notebook trains and evaluates survival models:\n",
        "- Cox Proportional Hazards\n",
        "- XGBoost Survival\n",
        "- Other survival models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sksurv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlifelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoxPHFitter\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_concordance_index, compute_td_auc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\survival-readmission\\app\\evaluation.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterable, Tuple\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msksurv\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     concordance_index_censored,\n\u001b[32m     15\u001b[39m     cumulative_dynamic_auc,\n\u001b[32m     16\u001b[39m     integrated_brier_score,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_concordance_index\u001b[39m(event: Iterable[\u001b[38;5;28mint\u001b[39m], time: Iterable[\u001b[38;5;28mfloat\u001b[39m], risk_scores: Iterable[\u001b[38;5;28mfloat\u001b[39m]) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute Harrell's C-index.\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \u001b[33;03m        C-index in [0, 1].\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sksurv'"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lifelines import CoxPHFitter\n",
        "from app.evaluation import compute_concordance_index, compute_td_auc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Feature Importance (Tree-based proxy)\n",
        "\n",
        "As a fast heuristic, train a tree-based classifier on the 30-day event label to inspect feature importances. This is a proxy (not a survival objective) to surface candidate predictors; we will follow up with survival-specific modeling (Cox, XGBoost Survival).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cohort and build features\n",
        "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n",
        "\n",
        "# Build features via app.feature_engineering (includes labs when available)\n",
        "from app.feature_engineering import engineer_features\n",
        "import os\n",
        "\n",
        "# Set the MIMIC_DEMO_DIR environment variable to ensure data loader finds the data\n",
        "os.environ['MIMIC_DEMO_DIR'] = '../data/raw/mimic-iv-demo'\n",
        "\n",
        "X, y_df = engineer_features(cohort)\n",
        "y = y_df['event'].astype(int)\n",
        "\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Num lab-derived columns:', sum([1 for col in X.columns if str(col).startswith('lab_')]))\n",
        "print('Sample lab columns:', [col for col in X.columns if str(col).startswith('lab_')][:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split and RandomForest quick AUC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Simple train/test split by index (for demo; prefer temporal split in practice)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Event rate in train: {y_train.mean():.3f}\")\n",
        "print(f\"Event rate in test: {y_test.mean():.3f}\")\n",
        "\n",
        "# Quick RandomForest for feature importance (proxy, not survival-specific)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Quick AUC (30-day classification proxy)\n",
        "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"Quick AUC (30-day classification proxy): {auc:.3f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 15 features:\")\n",
        "print(feature_importance.head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cohort from previous step (ensure variable exists before feature engineering)\n",
        "import pandas as pd\n",
        "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix shape: (260, 20)\n",
            "Num lab-derived columns: 0\n"
          ]
        }
      ],
      "source": [
        "# Build features via app.feature_engineering (includes labs when available)\n",
        "from app.feature_engineering import engineer_features\n",
        "\n",
        "X, y_df = engineer_features(cohort)\n",
        "y = y_df['event'].astype(int)\n",
        "\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Num lab-derived columns:', sum([1 for col in X.columns if str(col).startswith('lab_')]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: C:\\Users\\Golds\\Downloads\\survival-readmission\n"
          ]
        }
      ],
      "source": [
        "# Setup: add repo root to path for `app.*`\n",
        "import sys\n",
        "from pathlib import Path\n",
        "repo_root = (Path.cwd() / '..').resolve()\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print('Repo root:', repo_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cox Proportional Hazards (baseline)\n",
        "Fit an interpretable Cox PH model and report C-index on a holdout split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Cox PH\n",
        "from lifelines import CoxPHFitter\n",
        "from app.evaluation import compute_concordance_index\n",
        "\n",
        "cox_df = X.copy()\n",
        "cox_df[\"time_to_event\"] = y_df[\"time_to_event\"].values\n",
        "cox_df[\"event\"] = y_df[\"event\"].values\n",
        "\n",
        "# Simple train/test split by index (for demo; prefer temporal split in practice)\n",
        "train_idx, test_idx = X_train.index, X_test.index\n",
        "cox_train = cox_df.loc[train_idx]\n",
        "cox_test = cox_df.loc[test_idx]\n",
        "\n",
        "cph = CoxPHFitter(penalizer=0.1, l1_ratio=0.1)\n",
        "cph.fit(cox_train.assign(event=cox_train[\"event\"].astype(bool)), duration_col=\"time_to_event\", event_col=\"event\", show_progress=False)\n",
        "\n",
        "# Risk scores and C-index\n",
        "risk_scores = cph.predict_partial_hazard(cox_test)\n",
        "c_index = compute_concordance_index(cox_test[\"event\"], cox_test[\"time_to_event\"], risk_scores)\n",
        "print(f\"Cox PH C-index (holdout): {c_index:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost Survival (Cox objective)\n",
        "Train an XGBoost model with survival:cox to produce risk scores and compute C-index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Prepare DMatrix for XGBoost Cox\n",
        "# For Cox, label is time; event is provided implicitly via order weighting\n",
        "# We'll follow the typical approach: sort by time and pass (time, event) via special settings.\n",
        "\n",
        "# Create DMatrix with features\n",
        "dtrain = xgb.DMatrix(X_train, label=y_df.loc[X_train.index, 'time_to_event'].values)\n",
        "dtest = xgb.DMatrix(X_test, label=y_df.loc[X_test.index, 'time_to_event'].values)\n",
        "\n",
        "params = {\n",
        "    'objective': 'survival:cox',\n",
        "    'eval_metric': 'cox-nloglik',\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 3,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "bst = xgb.train(params, dtrain, num_boost_round=300)\n",
        "\n",
        "# XGBoost Cox produces risk scores as predictions\n",
        "xgb_risk = bst.predict(dtest)\n",
        "cox_cindex = compute_concordance_index(\n",
        "    y_df.loc[X_test.index, 'event'].values,\n",
        "    y_df.loc[X_test.index, 'time_to_event'].values,\n",
        "    xgb_risk,\n",
        ")\n",
        "print(f\"XGBoost Cox C-index (holdout): {cox_cindex:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split and RF model (ensure X_train/X_test defined)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "mask = X.notna().all(axis=1)\n",
        "Xc = X[mask]\n",
        "yc = y[mask]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=0.3, random_state=42, stratify=yc)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n",
        "proba = clf.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "print(f'Quick AUC (30-day classification proxy): {auc:.3f}')\n",
        "\n",
        "imp = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "print('Top 15 features:\\n', imp.head(15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build features via app.feature_engineering (includes labs when available)\n",
        "from app.feature_engineering import engineer_features\n",
        "\n",
        "X, y_df = engineer_features(cohort)\n",
        "y = y_df['event'].astype(int)\n",
        "\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Num lab-derived columns:', sum(col.startswith('\"lab_\"') for col in X.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quick AUC (30-day classification proxy): 0.576\n",
            "Top 15 features:\n",
            " age_at_discharge                                   0.401644\n",
            "gender_M                                           0.081105\n",
            "discharge_location_SKILLED NURSING FACILITY        0.060272\n",
            "insurance_Medicare                                 0.050945\n",
            "insurance_Other                                    0.050063\n",
            "admission_type_EW EMER.                            0.049381\n",
            "discharge_location_HOME                            0.048827\n",
            "admission_type_DIRECT EMER.                        0.038194\n",
            "discharge_location_HOME HEALTH CARE                0.034777\n",
            "admission_type_OBSERVATION ADMIT                   0.031774\n",
            "admission_type_URGENT                              0.028284\n",
            "discharge_location_REHAB                           0.024051\n",
            "discharge_location_CHRONIC/LONG TERM ACUTE CARE    0.022864\n",
            "admission_type_SURGICAL SAME DAY ADMISSION         0.020727\n",
            "admission_type_EU OBSERVATION                      0.013956\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load cohort from previous step\n",
        "cohort = pd.read_csv('../data/processed/cohort_30d.csv', parse_dates=['admittime','dischtime','next_admittime'])\n",
        "\n",
        "# Basic numeric/categorical feature set for quick pass\n",
        "X_cols = []\n",
        "for c in ['age_at_discharge','los_days']:\n",
        "    if c in cohort.columns:\n",
        "        X_cols.append(c)\n",
        "\n",
        "# One-hot encode a few categoricals\n",
        "cat_cols = [c for c in ['gender','admission_type','discharge_location','insurance'] if c in cohort.columns]\n",
        "X = pd.get_dummies(cohort[X_cols + cat_cols], drop_first=True)\n",
        "y = cohort['event'].astype(int)\n",
        "\n",
        "# Drop rows with any NA in features\n",
        "mask = X.notna().all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# AUC as quick heuristic\n",
        "proba = clf.predict_proba(X_test)[:,1]\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "print(f\"Quick AUC (30-day classification proxy): {auc:.3f}\")\n",
        "\n",
        "# Feature importance\n",
        "imp = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"Top 15 features:\\n\", imp.head(15))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
